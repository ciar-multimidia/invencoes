<!DOCTYPE html>
<html lang='pt-br'>
	<head>	
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-22690278-7"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-22690278-7');
</script>


		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>Acessibilidade para quem?</title>
		<link rel="stylesheet" href="../../../css/style.css">
		
	</head>
	<body>
		<header>
			<h1>Tecnologias assistivas na Universidade Federal de Espírito Santo (UFES)</h1>
			<div class="organizacao">
				<h2>Autores</h2>
				<div class="membro cdescricao">
				<p class="nome">Teodiano Freire Bastos Filho</p>
				<div class="descricao"><p><i>Teodiano Freire Bastos Filho</i> possui Graduação em Engenharia Elétrica pela Universidade Federal do Espírito Santo (1987, Vitória-ES), Especialização (2 anos) em Automação Industrial, pelo Instituto de Automática Industrial (1989, Madri, Espanha), Doutorado em Ciencias Físicas (Electricidad y Electrónica) pela Universidad Complutense de Madrid (1994, Madri, Espanha), e Pós-Doutorado em Interfaces Cérebro-Computador no Departamento de Electrónica da Universidad de Alcalá (2005, Alcalá de Henares, Espanha), e em Próteses Mioelétricas de Membro Superior na School of Electrical and Computer Engineering da RMIT University (2012, Melbourne, Austrália). Atualmente é Pesquisador Nível 1 do CNPq e Professor Titular da Universidade Federal do Espírito Santo, atuando no Programa de Pós-Graduação em Engenharia Elétrica, Programa de Pós-Graduação em Biotecnologia, e Doutorado RENORBIO. Tem experiência na área de Engenharia Elétrica, com ênfase em Sistemas Eletrônicos de Medida e de Controle, atuando principalmente nos seguintes temas: sensores, controle, robôs móveis, robótica industrial, robótica de reabilitação, tecnologia assistiva e processamento de sinais biológicos (SEMG, EOG, ECG e EEG).</p>
				</p></div>
				</div>
			</div>
		</header>
		<article>


			<h2>Introdução</h2>
			<p>O Núcleo de Tecnologia Assistiva (NTA/UFES - “Núcleo Nascente”) do Programa de Pós-Graduação em Engenharia Elétrica (PPGEE) da Universidade Federal do Espírito Santo (UFES) é coordenado pelo Prof. Dr. Teodiano Freire Bastos Filho e composto pela professora Eliete Maria de Oliveira Caldeira e pelos professores doutores Anselmo Frizera Neto e André Ferreira. Há ainda 20 alunos de doutorado e 9 de mestrado (tanto do PPGEE quando do Programa de Pós-Graduação em Biotecnologia – PPGBiotec) que também fazem parte do grupo, além de estudantes do Doutorado RENORBIO (Rede Nordeste de Biotecnologia). </p>
			<p>O núcleo realiza, desde 1997, pesquisas sobre sistemas, equipamentos, dispositivos e interfaces de ajuda a pessoas com deficiência. As pesquisas que vêm sendo desenvolvidas no NTA/UFES se encaixam nas seguintes áreas:</p>

			<h2>Órteses e próteses</h2>
			<p>Em 1999, após o desenvolvimento de sensores mioelétricos no ano de 1997, foi desenvolvida a primeira prótese multisensorial de membro superior do Brasil (Fig. 1), com ampla divulgação científica na época, em congressos nacionais e internacionais. A prótese desenvolvida possui as seguintes características:</p>
			<p><strong>•</strong> Uso de microcontrolador PIC para comando da eletrônica de acionamento da mão artificial, com base nos seguintes sensores:</p>
			<p><strong>a.</strong> Mioelétrico; </p>
			<p><strong>b.</strong> Temperatura (sensores KTY e rede de linearização); </p>
			<p><strong>c.</strong> Força e Deslizamento (sensores FSR);</p>
			<p><strong>d.</strong>  Nível de Bateria (rede de resistores);</p>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 1 - Prótese multisensorial de membro superior.</figcaption>
			</figure> --> 

			<p><strong>•</strong> O microcontrolador efetua o controle da seguinte forma: Se a temperatura estiver acima de 45oC, o usuário é alertado (por vibradores). Se a temperatura estiver acima de 60oC, o controlador não permite o fechamento da mão artificial. Se o objeto começar a deslizar ao ser levantado pela mão artificial, o controlador exerce mais força sobre o objeto até que ele deixe de deslizar.</p>

			<h2>Auxílios para qualificação da habilidade visual e recursos que ampliam a informação para pessoas com baixa visão ou cegas</h2>
			<p>Nos anos de 2002 e 2003 foram desenvolvidos dois sistemas de ajuda à mobilidade de pessoas com baixa visão ou cegas, avaliados positivamente em testes realizados por voluntários cegos do “Instituto Luiz Braille do Espírito Santo”. Os dispositivos possuem as seguintes características:</p>
			<p><strong>•</strong> Pochete Ultrassônica para Deficientes Visuais (Fig. 2a), com as seguintes características:</p>
			<p><strong>a.</strong> Permite detecção de obstáculos até a altura do tórax;</p>
			<p><strong>b.</strong> Opera com bateria recarregável;</p>
			<p><strong>c.</strong> Utiliza dois vibradores para alertar sobre a existência de obstáculos próximos;</p>

			<p><strong>•</strong> Colete Ultrassônico (Fig. 2b), com as seguintes características:</p>
			<p><strong>a.</strong> Permite a detecção de obstáculo até a altura da cabeça;</p>
			<p><strong>b.</strong> Eletrônica reduzida;</p>
			<p><strong>c.</strong> Opera com bateria recarregável;</p>
			<p><strong>d.</strong> Utiliza dois vibradores para alertar sobre a existência de obstáculos próximos;</p>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 2A - Sistemas de ajuda à mobilidade de pessoas cegas, baseados em sensores de ultrassom: Pochete.</figcaption>
			</figure> --> 

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 2B - Sistemas de ajuda à mobilidade de pessoas cegas, baseados em sensores de ultrassom: Colete.</figcaption>
			</figure> --> 

			<h2>Auxílios para a vida diária e prática</h2>
			<p>Ainda no ano 2004, foi desenvolvido um dispositivo de comunicação entre deficientes visuais e motoristas de ônibus, também avaliado positivamente em testes realizados por voluntários cegos do “Instituto Luiz Braille do Espírito Santo”.</p>
			<p>O deficiente visual, ao chegar à parada de ônibus, aciona o transmissor de rádio-frequência. O motorista de ônibus saberá com antecedência (a uma distância menor do que 150 m) a existência de um deficiente visual na próxima parada de ônibus. Avaliamos que o dispositivo proporciona independência ao deficiente visual.</p>
			<p>O dispositivo possui as seguintes características:</p>
			<p><strong>•</strong> Circuito baseado em microcontrolador PIC.</p>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 3 - Dispositivo de comunicação entre pessoas cegas e motorista de ônibus.</figcaption>
			</figure> --> 

			<h2>Auxílios para a vida diária e prática</h2>
			<p>Em 2005 começaram as pesquisas sobre processamento de sinais biomédicos aplicados a uma cadeira de rodas robótica. E no ano de 2009, o NTA desenvolveu a primeira cadeira de rodas robótica multimodal do mundo, com controlador dinâmico adaptativo (Fig. 4), capaz de seguir caminhos pré-definidos por trilhos metálicos (utilizando sensores magnéticos), ou comandada por várias modalidades: piscadas de olhos (sinais sEMG), movimento do globo ocular (VOG), movimentos de cabeça (IMU), sopro ou sucção (sensor de pressão), e até por sinais cerebrais (EEG de distintos padrões: concentração/relaxamento – ERD/ERS –, potenciais evocados visuais de estado permanente – SSVEP –, e imaginação motora). A referida cadeira de rodas foi amplamente reportada pela mídia nacional, além de divulgação em congressos nacionais e internacionais e também em periódicos científicos internacionais de primeira linha. Este sistema assistivo foi patenteado, com o título “Sistema Assistivo de Interface Homem-Máquina”, com o Número do Registro no INPI PI1006321 e data de Depósito em 20 de julho de 2010.</p>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 4 - Diferentes imagens da cadeira de rodas robótica multimodal da UFES.</figcaption>
			</figure> --> 


			<p>Ainda no que se refere ao sistema de ajuda à mobilidade, em 2013 o núcleo desenvolveu um andador robótico (Fig. 5) que ajuda na mobilidade de pessoas com deficiência motora leve e moderada (que podem caminhar, mas somente com auxílio). O sistema utiliza sensores de força, localizados nos apoios de antebraço, para detectar a intenção de movimento do usuário, além deum sensor laser para detectar a distância das pernas e assim inferir a velocidade de marcha do usuário.</p>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 5 - Andador robótico de ajuda à mobilidade de pessoas com deficiência.</figcaption>
			</figure> --> 

			<h2>CAA - Comunicação aumentativa e/ou alternativa</h2>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 6A - Sistema de comunicação alternativa instalado no PDA localizado a bordo da cadeira de rodas robótica.</figcaption>
			</figure> --> 

			<p>No ano 2009, desenvolvemos um sistema (instalado em um PDA localizado na cadeira de rodas robótica) (Fig. 6), que permitia ao cadeirante comunicar-se de forma alternativa, utilizando quaisquer das modalidades (piscadas de olhos, movimento do globo ocular, movimentos de cabeça, sopro ou sucção, ou sinais cerebrais) para selecionar letras do alfabeto e compor palavras e frases, utilizando um sistema preditivo, ou selecionar símbolos pictográficos associados a estados de necessidade ou sentimento. Uma vez selecionado o texto ou símbolo, um comando voz artificial é emitido através de duas caixas de som da cadeira de rodas robótica.</p>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 6B - Sistema de comunicação alternativa instalado no PDA localizado a bordo da cadeira de rodas robótica.</figcaption>
			</figure> --> 

			<h2>Robôs para interação com crianças com deficiência motora severa e autismo</h2>
			<p>No ano de 2011 foi desenvolvido o robô móvel Nino, projetado para ser comandado por crianças com deficiências motoras severas (Fig. 7) para que estas pudessem interagir com o ambiente através do robô. Assim, as crianças podem utilizar qualquer movimento voluntário, enquanto os sensores mioelétrico (sEMG) e de inclinação (baseado em acelerômetro), localizados em partes do corpo da criança (cabeça, braço, perna, etc), capturam tanto a contração ou distensão muscular quanto a inclinação da parte do corpo onde o sensor está instalado. Esses sinais são transmitidos, sem fio (wireless) ao robô móvel, para que este realize operações de agarrar, trazer e levar objetos, ou até mesmo desenhar sobre papel.</p>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 7- Robô Nino utilizado por crianças com deficiência motora severa.</figcaption>
			</figure> --> 

			<p>No ano de 2014 o NTA desenvolveu um robô móvel para interação com crianças com autismo. O robô foi denominado MARIA, um acrônimo em inglês <i>(Mobile Autonomous Robot for Interaction with Autistics)</i> que significa “Robô Móvel Autônomo para Interação com Autistas” (Fig. 8a). O robô é dotado de sistema multimídia (monitor de vídeo e alto-falantes) que reproduz filmes infantis para atrair a atenção das crianças. Além disso, o robô possui câmera de vídeo para registrar as expressões faciais das crianças, além de um sensor laser para obter a localização da criança em cada momento. Esses sensores têm por finalidade verificar as emoções (pelas expressões faciais) e a proximidade da criança ao robô (para analisar conceitos de proximetria, os quais se referem à interação social entre a criança e o robô). Vários experimentos foram feitos com crianças com autismo (com registro de seus padrões de sinais cerebrais através de uma touca de EEG sem fios, para também determinar padrões de emoções evocados nas crianças). A finalidade desta pesquisa é utilizar o robô como intermediário para fortalecer a interação entre as crianças com autismo e as demais pessoas do seu convívio. Em 2017, foi desenvolvida uma nova versão do robô MARIA, denominada N-MARIA, ou Nova-MARIA (<i>New MARIA</i>, em inglês). Nesta nova versão do robô, foram incluídos um novo sensor laser (omnidirecional) e uma câmera térmica (de forma a verificar o rubor da pele da criança com autismo, associado a emoções). A face do robô também foi modificada e substituída por um tablet, capaz de representar faces dinâmicas (com movimentos de boca e olhos).</p>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 8A - Robô móvel MARIA, utilizado para melhorar a interação social de crianças com autismo; 8B Nova versão do robô MARIA, denominado N-MARIA.</figcaption>
			</figure> --> 

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 8B - Nova versão do robô MARIA, denominado N-MARIA.</figcaption>
			</figure> --> 	

			<h2>Adaptações em veículos</h2>
			<p>Desde 2013, um novo projeto de pesquisa em desenvolvimento (em conjunto com o Programa de Pós-Graduação em Informática da UFES), pretende permitir que uma pessoa com deficiência motora severa possa comandar um veículo da marca Ford, modelo <i>Escape Hybrid</i>, por sinais cerebrais (Fig. 9), equipado com sistemas de controle de acelerador, freio, marcha, luzes, buzina e sensores de odometria, posição do volante e rotação do motor. O veículo possui também um sistema laser LIDAR <i>(Light Detection And Ranging)</i>, câmeras de vídeo de alta velocidade de transmissão de dados <i>(firewire)</i>, GPS e sensor inercial 6D <i>(IMU – Inertial Measurement Unit)</i>, os quais são utilizados para a localização do veículo e mapeamento do ambiente, através do uso de técnicas de SLAM <i>(Simultaneous Localization and Mapping)</i>.</p>

			<!-- <figure>
				<img src="imagens/cap1/imagem001.jpg" alt="">
				<figcaption>Figura 9 - Veículo instrumentalizado para comando por pessoas com deficiência motora severa, através de sinais cerebrais.</figcaption>
			</figure> --> 

			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>
			<p></p>




		</article>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.js"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-touch-events/1.0.5/jquery.mobile-events.js"></script>
		<script src="../../../js/script.js"></script>
		<script src="../../../js/dados_livros.js"></script>
	</body>
</html>